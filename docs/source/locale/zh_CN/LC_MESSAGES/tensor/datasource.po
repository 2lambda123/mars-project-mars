# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-2018, The Alibaba Group Holding Ltd.
# This file is distributed under the same license as the mars package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: mars \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-05-04 11:03+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.3\n"

#: ../../source/tensor/datasource.rst:2
msgid "Create Mars tensor"
msgstr ""

#: ../../source/tensor/datasource.rst:4
msgid ""
"You can create mars tensor from Python array like object just like Numpy,"
" or create from Numpy array directly. More details on :doc:`array "
"creation routine <routines/creation>` and :doc:`random sampling "
"<routines/random>`."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`mars.tensor.tensor <mars.tensor.tensor>`"
msgstr ""

#: ../../<autosummary>:1
msgid "Create a tensor."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`mars.tensor.array <mars.tensor.array>`"
msgstr ""

#: ../../source/tensor/datasource.rst:16
msgid "Create tensor on GPU"
msgstr ""

#: ../../source/tensor/datasource.rst:18
msgid ""
"Mars tensor can run on GPU, for tensor creation, just add a ``gpu`` "
"parameter, and set it to ``True``."
msgstr ""

#: ../../source/tensor/datasource.rst:28
msgid "Create sparse tensor"
msgstr ""

#: ../../source/tensor/datasource.rst:30
msgid ""
"Mars tensor can be sparse, unfortunately, only 2-D sparse tensors are "
"supported for now, multi-dimensional tensor will be supported later soon."
msgstr ""

#: ../../source/tensor/datasource.rst:41
msgid "Chunks"
msgstr ""

#: ../../source/tensor/datasource.rst:43
msgid ""
"In mars tensor, we tile a tensor into small chunks. Argument ``chunks`` "
"is not always required, a chunk's bytes occupation will be 128M for the "
"default setting. However, user can specify each chunk's size in a more "
"flexible way which may be adaptive to the data scale. The fact is that "
"chunk's size may effect heavily on the performance of execution."
msgstr ""

#: ../../source/tensor/datasource.rst:48
msgid ""
"The options or arguments which will effect the chunk's size are listed "
"below:"
msgstr ""

#: ../../source/tensor/datasource.rst:50
msgid ""
"Change ``options.tensor.chunk_size_limit`` which is 128*1024*1024(128M) "
"by default."
msgstr ""

#: ../../source/tensor/datasource.rst:51
msgid ""
"Specify ``chunks`` as integer, like ``5000``, means chunk's size is 5000 "
"at most for all dimensions"
msgstr ""

#: ../../source/tensor/datasource.rst:52
msgid "Specify ``chunks`` as tuple, like ``(5000, 3000)``"
msgstr ""

#: ../../source/tensor/datasource.rst:53
msgid ""
"Explicitly define sizes of all chunks along all dimensions, like "
"``((5000, 5000, 2000), (2000, 1000))``"
msgstr ""

#: ../../source/tensor/datasource.rst:56
msgid "Chunks Examples"
msgstr ""

#: ../../source/tensor/datasource.rst:58
msgid "Assume we have such a tensor with the data shown below."
msgstr ""

#: ../../source/tensor/datasource.rst:71
msgid "We will show how different ``chunks=`` arguments will tile the tensor."
msgstr ""

#: ../../source/tensor/datasource.rst:73
msgid "``chunks=3``:"
msgstr ""

#: ../../source/tensor/datasource.rst:88
msgid "``chunks=2``:"
msgstr ""

#: ../../source/tensor/datasource.rst:104
msgid "``chunks=(3, 2)``:"
msgstr ""

#: ../../source/tensor/datasource.rst:119
msgid "``chunks=((3, 1, 2, 2), (3, 2, 1))``:"
msgstr ""

